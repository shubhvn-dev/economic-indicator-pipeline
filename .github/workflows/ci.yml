name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  lint:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r airflow/requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Run Black formatter check
      run: black --check airflow/ spark/ streamlit/
    
    - name: Run isort import sorting check
      run: isort --check-only airflow/ spark/ streamlit/
    
    - name: Run flake8 linting
      run: flake8 airflow/ spark/ streamlit/ --max-line-length=100 --ignore=E501,W503

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        # Install Apache Airflow with constraints for Python 3.11
        AIRFLOW_VERSION=2.8.1
        PYTHON_VERSION="$(python --version | cut -d " " -f 2 | cut -d "." -f 1-2)"
        CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
        pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
        # Install other dependencies
        pip install -r airflow/requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Initialize Airflow DB
      run: |
        export AIRFLOW_HOME=${GITHUB_WORKSPACE}/airflow
        airflow db init
      env:
        AIRFLOW__CORE__LOAD_EXAMPLES: False
        AIRFLOW__CORE__DAGS_FOLDER: ${{ github.workspace }}/airflow/dags
    
    - name: Run unit tests
      run: pytest tests/unit/ -v --cov=. --cov-report=xml
    
    - name: Run DAG validation tests
      run: pytest tests/dags/ -v
      env:
        AIRFLOW_HOME: ${{ github.workspace }}/airflow
        AIRFLOW__CORE__DAGS_FOLDER: ${{ github.workspace }}/airflow/dags
        AIRFLOW__CORE__LOAD_EXAMPLES: False
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false

  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Build Airflow image
      run: |
        docker build -t economic-pipeline:test -f airflow/Dockerfile airflow/
    
    - name: Test docker-compose configuration
      run: |
        docker compose config

  dbt-test:
    name: dbt Tests
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install dbt-core==1.7.4 dbt-duckdb==1.7.1 pandas pyarrow duckdb
    
    - name: Create dummy data
      run: python tests/setup_dummy_data.py
    
    - name: dbt debug
      run: |
        cd dbt
        dbt debug --profiles-dir .
    
    - name: dbt compile
      run: |
        cd dbt
        dbt compile --profiles-dir .

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    permissions:
      security-events: write
      contents: read
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy results to GitHub Security
      uses: github/codeql-action/upload-sarif@v3  # Changed v2 to v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'